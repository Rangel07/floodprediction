{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True # Save to file\n",
    "#------------------------\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from os import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "## Clean\n",
    "def clean(df, file, save = True):\n",
    "\n",
    "    df.columns = (list(df.iloc[2].values)) # Get column names\n",
    "    df = df.loc[:, df.columns.notnull()]   # Remove nan columns\n",
    "    df = df[~((df['Data / Hora'] == 'Data / Hora') &\n",
    "              (df['Pressão Atmosférica'] == 'Pressão Atmosférica'))] # Remove all headers\n",
    "\n",
    "    df = df[df.iloc[:,0].str.contains(':', na = False) &\n",
    "            df.iloc[:,0].str.contains('/', na = False)] # Get data rows only\n",
    "\n",
    "    df.insert(0, 'Data','')\n",
    "    df.insert(1, 'Hora','')\n",
    "    df[['Data', 'Hora']] = df['Data / Hora'].str.split(expand = True)\n",
    "    #df.drop('Data / Hora', axis = 1, inplace = True) # Split into 2 columns\n",
    "    \n",
    "    drop_cols = [4, 6, 7, 10, 12, 14, 15, 17, 20, 22 ]\n",
    "    #    drop_cols = [3, 5, 6, 9, 11, 12, 14, 16, 19, 2]\n",
    "    df = df.drop(df.columns[drop_cols],axis=1)\n",
    "\n",
    "    col_names = ['Data', 'Hora', 'Data / Hora',\n",
    "                 'UmidadeRelativa', 'PressaoAtmosferica',\n",
    "                 'Temperatura do Ar', 'TemperaturaInterna',\n",
    "                 'PontoDeOrvalho', 'SensacaoTermica',\n",
    "                 'RadiacaoSolar', 'DirecaoDoVento',\n",
    "                 'VelocidadeDoVento', 'Precipitacao']\n",
    "    df.columns = col_names   \n",
    "\n",
    "    df['Local'] = os.path.basename(file).split()[0].split('_')[0]\n",
    "\n",
    "    if save:\n",
    "        save_to_file(df, file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_to_file(df, file):\n",
    "    save_path = file.replace('rawdata', 'cleandata')\n",
    "    save_path = save_path.replace('.xls', '.csv')\n",
    "    #print('saving to ', save_path, '\\n')\n",
    "    df.to_csv(save_path, sep = ';', index = False)\n",
    "    \n",
    "    \n",
    "## Concatanate\n",
    "\n",
    "def concatanate(df_list, name, save = True):\n",
    "    if df_list:\n",
    "        df = pd.concat(df_list, axis = 0)\n",
    "        if save:\n",
    "            save_concat(df, name)\n",
    "            return df\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "def save_concat(df, name, path = './cleandata/Info pluviometricas/Concatanated Data/'):\n",
    "    file = os.path.join(path, name) + '.csv'\n",
    "    df.to_csv(file, sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './rawdata/Info pluviometricas'\n",
    "\n",
    "files = []\n",
    "directories = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    directories.extend(d)\n",
    "    for file in f:\n",
    "        if '.xls' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "            \n",
    "len(files) # Should be 90!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dir\n",
    "\n",
    "from os import mkdir\n",
    "\n",
    "if not os.path.exists(\"./cleandata\"):\n",
    "    mkdir('./cleandata')\n",
    "\n",
    "if not os.path.exists(\"./cleandata/Info pluviometricas\"):\n",
    "    mkdir('./cleandata/Info pluviometricas')\n",
    "    \n",
    "if not os.path.exists(\"./cleandata/Info pluviometricas/Concatanated Data/\"):\n",
    "    mkdir('./cleandata/Info pluviometricas/Concatanated Data/')\n",
    "    \n",
    "for directory in directories:\n",
    "    path_ = os.path.join(\"./cleandata/Info pluviometricas\", directory)\n",
    "    if not os.path.exists(path_):\n",
    "        mkdir(path_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "1/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "2/90\n",
      "3/90\n",
      "4/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "5/90\n",
      "6/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "7/90\n",
      "8/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "9/90\n",
      "10/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "11/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "12/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "13/90\n",
      "14/90\n",
      "15/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "16/90\n",
      "17/90\n",
      "18/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "19/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "20/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "21/90\n",
      "22/90\n",
      "23/90\n",
      "24/90\n",
      "25/90\n",
      "26/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "27/90\n",
      "28/90\n",
      "29/90\n",
      "30/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "31/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "32/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "33/90\n",
      "34/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "35/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "36/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "37/90\n",
      "38/90\n",
      "39/90\n",
      "40/90\n",
      "41/90\n",
      "42/90\n",
      "43/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "44/90\n",
      "45/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "46/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "47/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "48/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "49/90\n",
      "50/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "51/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "52/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "53/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "54/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "55/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "56/90\n",
      "57/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "58/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "59/90\n",
      "60/90\n",
      "61/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "62/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "63/90\n",
      "64/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "65/90\n",
      "66/90\n",
      "67/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "68/90\n",
      "69/90\n",
      "70/90\n",
      "71/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "72/90\n",
      "73/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "74/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "75/90\n",
      "76/90\n",
      "77/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "78/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "79/90\n",
      "80/90\n",
      "81/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "82/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "83/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "84/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "85/90\n",
      "86/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "87/90\n",
      "88/90\n",
      "89/90\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "dic = {directory: [] for directory in directories}\n",
    "\n",
    "#Load cleaned data into dictonary\n",
    "i = 0\n",
    "for file in files:\n",
    "    for d in directories:\n",
    "        if d in file:\n",
    "            print(f'{i}/{len(files)}')\n",
    "            filename = os.path.basename(file)\n",
    "            df = pd.read_excel(file)\n",
    "            dic[d].append( clean(df, file, SAVE) )\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatanate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatanated = {}\n",
    "if SAVE:\n",
    "    for d in directories:\n",
    "        concatanated[d] = concatanate(dic[d], d, SAVE) # Concatanate and save\n",
    "else:\n",
    "    for d in directories:\n",
    "        concatanated[d] = concatanate(dic[d], d, SAVE) # Concatanate and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(concatanated.keys())\n",
    "estacao0 = concatanated[keys[0]].copy( deep = True)\n",
    "estacao1 = concatanated[keys[1]].copy( deep = True)\n",
    "estacao2 = concatanated[keys[2]].copy( deep = True)\n",
    "estacao3 = concatanated[keys[3]].copy( deep = True)\n",
    "estacao4 = concatanated[keys[4]].copy( deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacao4.drop(columns=['Data', 'Hora'], inplace = True)\n",
    "\n",
    "new_cols = []\n",
    "for col in estacao4.columns:\n",
    "    if col != 'Data / Hora':\n",
    "        col = col + '_4'\n",
    "    new_cols.append(col)\n",
    "    \n",
    "estacao4.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacao0.drop(columns=['Data', 'Hora'], inplace = True)\n",
    "estacao1.drop(columns=['Data', 'Hora'], inplace = True)\n",
    "merge1 = estacao0.merge(estacao1, on = 'Data / Hora', how = 'outer', suffixes = ('_0', '_1'))\n",
    "\n",
    "estacao2.drop(columns=['Data', 'Hora'], inplace = True)\n",
    "estacao3.drop(columns=['Data', 'Hora'], inplace = True)\n",
    "merge2 = estacao2.merge(estacao3, on = 'Data / Hora', how = 'outer', suffixes = ('_2', '_3'))\n",
    "\n",
    "merge3 = merge1.merge(merge2, on = 'Data / Hora', how = 'outer')\n",
    "merged = merge3.merge(estacao4, on = 'Data / Hora', how = 'outer')\n",
    "\n",
    "merged.insert(0, 'Data','')\n",
    "merged.insert(1, 'Hora','')\n",
    "df[['Data', 'Hora']] = merged['Data / Hora'].str.split(expand = True)\n",
    "\n",
    "if SAVE:\n",
    "    if not os.path.isdir('./cleandata/Info pluviometricas/Merged Data/'):\n",
    "        mkdir('./cleandata/Info pluviometricas/Merged Data/')\n",
    "    \n",
    "    merged.to_csv('./cleandata/Info pluviometricas/Merged Data/merged.csv',\n",
    "                  decimal = ',', sep = ';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
