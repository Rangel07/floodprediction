{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score,\\\n",
    "                            recall_score, fbeta_score, precision_recall_curve\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hyperopt import hp\n",
    "import hyperopt.pyll\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../Pipeline')\n",
    "\n",
    "from ml_utils import plot_confusion_matrix, plot_precision_recall, arg_nearest\n",
    "from utils import moving_average, reverse_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../../../data/cleandata/Info pluviometricas/Merged Data/repaired.csv', sep = ';')\n",
    "original_df['Data_Hora'] = pd.to_datetime(original_df['Data_Hora'])\n",
    "original_df['Date'] = original_df['Data_Hora'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols = list({c.split('_')[0] for c in original_df.columns if '_error' in c})\n",
    "interest_cols.remove('TemperaturaInterna')\n",
    "interest_cols.remove('SensacaoTermica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Stations - Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in interest_cols:\n",
    "#     original_df[c] = (original_df[c+'_0'] + original_df[c+'_1'] +\n",
    "#                       original_df[c+'_2'] + original_df[c+'_3'] + original_df[c+'_4'])/5 \n",
    "    original_df[c] = original_df[c+'_0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = original_df[original_df.Data_Hora.dt.year == 2015]\n",
    "\n",
    "fig = go.Figure(layout=dict(template = 'plotly_dark'))\n",
    "\n",
    "for col in ['PontoDeOrvalho', 'Precipitacao', 'UmidadeRelativa', 'TemperaturaDoAr']:    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = df_plot['Data_Hora'],\n",
    "        y = df_plot[col],\n",
    "        name = col,\n",
    "                            )\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols += ['Diff_Temp_POrvalho']\n",
    "original_df['Diff_Temp_POrvalho'] = original_df['TemperaturaDoAr'] -  original_df['PontoDeOrvalho']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 6H-wise DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 6\n",
    "\n",
    "unique_values = np.arange(0, len(original_df), 1)\n",
    "n_group = hours * 4\n",
    "\n",
    "h_id = np.repeat(unique_values, n_group)\n",
    "original_df['h_id'] = h_id[:len(original_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = original_df.groupby('h_id').count().iloc[:,0] < n_group\n",
    "drop_rows = drop_rows[drop_rows].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = original_df.groupby('h_id').count().iloc[:,0] < n_group\n",
    "drop_rows = drop_rows[drop_rows].index.to_list()\n",
    "\n",
    "for row in drop_rows:\n",
    "    original_df = original_df[original_df.h_id != row]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.loc[::n_group, ['Data_Hora','h_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = original_df.loc[::n_group, ['Data_Hora', 'h_id']].set_index('h_id').to_dict()['Data_Hora']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "has_rain_treshold = 10\n",
    "precipitacao_sum = original_df.loc[:, ['h_id', 'Precipitacao']].groupby('h_id').sum()\n",
    "precipitacao_sum.loc[:, 'Rain_Now'] = (precipitacao_sum['Precipitacao'] > has_rain_treshold ).astype(int)\n",
    "precipitacao_sum.loc[:, f'Rain_Next_{hours}H'] = precipitacao_sum.loc[:, 'Rain_Now'].shift(-1)\n",
    "precipitacao_sum = precipitacao_sum.dropna()\n",
    "\n",
    "# Remove last index (h_id) from original_df \n",
    "last_index = original_df.groupby('h_id').count().iloc[:,0].index[-1]\n",
    "original_df = original_df[original_df.h_id != last_index]\n",
    "\n",
    "precipitacao_sum.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = precipitacao_sum.loc[:, ['Rain_Now', f'Rain_Next_{hours}H']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum_df = original_df[interest_cols + ['h_id']].groupby('h_id').sum()\n",
    "sum_df.columns = [c + '_sum' for c in sum_df.columns]\n",
    "\n",
    "median_df = original_df[interest_cols + ['h_id']].groupby('h_id').median()\n",
    "median_df.columns = [c + '_median' for c in median_df.columns]\n",
    "\n",
    "mean_df = original_df[interest_cols + ['h_id']].groupby('h_id').mean()\n",
    "mean_df.columns = [c + '_mean' for c in mean_df.columns]\n",
    "\n",
    "min_df = original_df[interest_cols + ['h_id']].groupby('h_id').min()\n",
    "min_df.columns = [c + '_min' for c in min_df.columns]\n",
    "\n",
    "max_df = original_df[interest_cols + ['h_id']].groupby('h_id').max()\n",
    "max_df.columns = [c + '_max' for c in max_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df, mean_df], axis = 1)\n",
    "df = pd.concat([df, sum_df, mean_df, median_df, min_df, max_df], axis = 1)\n",
    "df.index = df.index.map(map_)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff_cols = interest_cols.copy()\n",
    "diff_cols.remove('VelocidadeDoVento')\n",
    "\n",
    "for col in diff_cols:\n",
    "    diff = original_df.loc[n_group-1::n_group, col].values -\\\n",
    "           original_df.loc[0::n_group, col].values\n",
    "    df[f'{col}_diff'] = diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_season(Row):\n",
    "    \n",
    "#     doy = Row.name.timetuple().tm_yday\n",
    "    \n",
    "#     fall_start = datetime.strptime('2020-03-20', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "#     summer_start = datetime.strptime('2020-06-20', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "#     spring_start = datetime.strptime('2020-09-22', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "#     spring_end = datetime.strptime('2020-12-21', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "    \n",
    "#     fall = range(fall_start, summer_start)\n",
    "#     summer = range(summer_start, spring_start)\n",
    "#     spring = range(spring_start, spring_end)\n",
    "    \n",
    "#     if doy in fall:\n",
    "#         season = 1#'fall'\n",
    "#     elif doy in summer:\n",
    "#         season = 2#'winter'\n",
    "#     elif doy in spring:\n",
    "#         season = 3#'spring'\n",
    "#     else:\n",
    "#         season = 0#'summer' \n",
    "    \n",
    "#     return season\n",
    "\n",
    "# df_date['season'] =  df_date.apply(get_season, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal_means = ['Precipitacao_mean']#, 'RadiacaoSolar_mean', 'TemperaturaDoAr_mean']\n",
    "\n",
    "# for s in seasonal_means:\n",
    "#     map_ = dict(df_date.groupby('season').mean()['Precipitacao_mean'])\n",
    "#     df_date[f'seasonalMean_{s}'] =  df_date['season'].map(map_)\n",
    "\n",
    "# df_date = df_date.drop(columns = ['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_date.corr()['Rain_Next_Day'].abs().sort_values(ascending = False).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df_date.corr()['Rain_Next_Day'].index,df_date.corr()['Rain_Next_Day'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = f'Rain_Next_{hours}H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns = [label]), df[label].astype(int).values\n",
    "\n",
    "X = X.drop(columns = 'Rain_Now')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(tree_method = 'gpu_hist')\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "clf.fit(X_train, y_train,  eval_metric=[\"logloss\",\"error\", \"auc\", \"map\"], eval_set=eval_set, verbose=False);\n",
    "\n",
    "keys = clf.evals_result()['validation_0'].keys()\n",
    "\n",
    "fig, ax = plt.subplots( 1, len(keys) ,figsize = (7*len(keys),7))\n",
    "ax = ax.ravel()\n",
    "for i, key in enumerate(keys):\n",
    "    ax[i].set_title(key)\n",
    "    ax[i].plot(clf.evals_result()['validation_0'][key], lw = 3)\n",
    "    ax[i].plot(clf.evals_result()['validation_1'][key], lw = 3)\n",
    "plt.show()\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "plot_confusion_matrix(y_test, y_pred, ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[label].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[217,:], X_test.iloc[217,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0:500, :], X_test.iloc[0:500, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,14))\n",
    "\n",
    "features_imp = dict(zip(X_train.columns, clf.feature_importances_))\n",
    "features_imp = {k: v for k, v in sorted(features_imp.items(), key=lambda item: item[1])}\n",
    "\n",
    "plt.barh(list(features_imp.keys()), features_imp.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(X_train.corr())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "colorscale=[[0.0, \"rgb(240, 0, 0)\"],\n",
    "            [0.3, \"rgb(240, 240, 239)\"],\n",
    "            [1.0, 'rgb(240, 240, 240)']]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Heatmap( z = X_train.corr(),\n",
    "                         x = X_train.columns,\n",
    "                         y = X_train.columns, \n",
    "                         colorscale = colorscale))\n",
    "fig.update_layout(width = 700, height = 700)\n",
    "fig.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_correlation(df, threshold):\n",
    "    \n",
    "    dataset = df.copy()\n",
    "    \n",
    "    remove_columns = []\n",
    "    \n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (np.abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    remove_columns.append(colname) # deleting the column from the dataset\n",
    "                    \n",
    "                    \n",
    "    return remove_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns = remove_high_correlation(X_train, 0.7)\n",
    "remove_columns += ['Precipitacao_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = X_test.drop(columns = remove_columns)\n",
    "X_train_sel = X_train.drop(columns = remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap( z = X_train_sel.corr(),\n",
    "                         x = X_train_sel.columns,\n",
    "                         y = X_train_sel.columns) )\n",
    "fig.update_layout(template = 'plotly_dark',width = 700, height = 700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()#tree_method = 'gpu_hist')\n",
    "\n",
    "eval_set = [(X_train_sel, y_train), (X_test_sel, y_test)]\n",
    "\n",
    "clf.fit(X_train_sel, y_train,  eval_metric=[\"logloss\",\"error\", \"auc\", \"map\"],\n",
    "        eval_set=eval_set, verbose=False, early_stopping_rounds=10,);\n",
    "\n",
    "keys = clf.evals_result()['validation_0'].keys()\n",
    "\n",
    "fig, ax = plt.subplots( 1, len(keys) ,figsize = (7*len(keys),7))\n",
    "ax = ax.ravel()\n",
    "for i, key in enumerate(keys):\n",
    "    ax[i].set_title(key)\n",
    "    ax[i].plot(clf.evals_result()['validation_0'][key], lw = 3)\n",
    "    ax[i].plot(clf.evals_result()['validation_1'][key], lw = 3)\n",
    "plt.show()\n",
    "\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "plot_confusion_matrix(y_test, y_pred, ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "\n",
    "features_imp = dict(zip(X_train_sel.columns, clf.feature_importances_))\n",
    "features_imp = {k: v for k, v in sorted(features_imp.items(), key=lambda item: item[1])}\n",
    "\n",
    "plt.barh(list(features_imp.keys()), features_imp.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_hyperopt = {\n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 5, 30, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 1000, 1)),\n",
    "    'min_child_weight':  scope.int(hp.quniform('min_child_weight', 1, 8, 1)),\n",
    "    'reg_lambda':hp.uniform('reg_lambda', 0.01, 500.0),\n",
    "    'reg_alpha':hp.uniform('reg_alpha', 0.01, 500.0),\n",
    "    'colsample_bytree':hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'early_stopping_rounds':  scope.int(hp.quniform('early_stopping_rounds', 1, 20, 1)),\n",
    "                 }\n",
    "\n",
    "def cost_function(params):\n",
    "    \n",
    "    fit_parameters = {}\n",
    "    fit_parameters['early_stopping_rounds'] = params.pop('early_stopping_rounds')\n",
    "\n",
    "    clf = xgb.XGBClassifier(**params,\n",
    "                            objective=\"binary:logistic\",\n",
    "                            random_state=42)\n",
    "\n",
    "    clf.fit(X_train_sel, y_train, eval_set = eval_set, eval_metric=[\"logloss\"], verbose = False,**fit_parameters)\n",
    "    y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "    return {'loss':-fbeta_score(y_test, y_pred, beta=2),'status': STATUS_OK}\n",
    "\n",
    "num_eval = 250\n",
    "eval_set = [(X_train_sel, y_train), (X_test_sel, y_test)]\n",
    "\n",
    "trials = Trials()\n",
    "best_param = fmin(cost_function,\n",
    "                     param_hyperopt,\n",
    "                     algo=tpe.suggest,\n",
    "                     max_evals=num_eval,\n",
    "                     trials=trials,\n",
    "                     rstate=np.random.RandomState(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param['min_child_weight'] = int(best_param['min_child_weight'])\n",
    "best_param['n_estimators'] = int(best_param['n_estimators'])\n",
    "best_param['max_depth'] = int(best_param['max_depth'])\n",
    "best_param['early_stopping_rounds'] = int(best_param['early_stopping_rounds'])\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_param.copy()\n",
    "\n",
    "fit_parameters = {}\n",
    "fit_parameters['early_stopping_rounds'] = params.pop('early_stopping_rounds')\n",
    "\n",
    "clf = xgb.XGBClassifier(**params,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        random_state=42)\n",
    "\n",
    "clf.fit(X_train_sel, y_train, eval_set = eval_set, eval_metric=[\"logloss\"],\n",
    "        verbose = False,**fit_parameters)\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "y_pred_prob = clf.predict_proba(X_test_sel)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, ['0','1'])\n",
    "evaluate = (y_test, y_pred)\n",
    "print('f1_score: ', f1_score(*evaluate))\n",
    "print('Accuracy: ', accuracy_score(*evaluate))\n",
    "print('Precision: ', precision_score(*evaluate))\n",
    "print('Recall: ', recall_score(*evaluate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(y_test, y_pred_prob[:,1])\n",
    "fig.update_layout(template = 'plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_recall = 0.8\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_prob[:,1])\n",
    "y_pred_threshold = (y_pred_prob[:,1] > threshold[arg_nearest(recall, desired_recall)]).astype(int)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_threshold, ['0','1'])\n",
    "evaluate = (y_test, y_pred_threshold)\n",
    "print('f1_score: ', f1_score(*evaluate))\n",
    "print('Accuracy: ', accuracy_score(*evaluate))\n",
    "print('Precision: ', precision_score(*evaluate))\n",
    "print('Recall: ', recall_score(*evaluate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Wind Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.read_csv('../../../data/cleandata/Info pluviometricas/Merged Data/error_regions.csv', sep = ';')\n",
    "errors[[c for c in errors.columns if 'Direcao' in c]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_wind = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_ = reverse_mod(original_df[f'DirecaoDoVento_{selected_wind}'].values)\n",
    "v_ = moving_average(rv_, window = 15)\n",
    "v_ = np.mod(v_, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=dict(template = 'plotly_dark'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "x= list(range(len(rv_))),\n",
    "y = rv_))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=dict(template = 'plotly_dark'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = original_df['Data_Hora'],\n",
    "    y = original_df[f'DirecaoDoVento_{selected_wind}'],\n",
    "    name = f'DirecaoDoVento_{selected_wind}',\n",
    "    line = dict(color = 'gray')),\n",
    "             )\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = original_df['Data_Hora'],\n",
    "    y = v_,\n",
    "    name = 'Avg'),\n",
    "             )\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_direction = np.empty(v_.shape, dtype = np.int)\n",
    "wind_direction[(v_ > 315 ) | (v_ <=  45 )] = 0 # North\n",
    "wind_direction[(v_ >  45 ) & (v_ <= 135 )] = 1 # East\n",
    "wind_direction[(v_ > 135 ) & (v_ <= 225 )] = 2 # South\n",
    "wind_direction[(v_ > 225 ) & (v_ <= 315 )] = 3 # West\n",
    "\n",
    "original_df['DirecaoDoVento_cat'] = wind_direction\n",
    "original_df['Date'] = pd.to_datetime(original_df['Date'], yearfirst=True)\n",
    "\n",
    "# Mode\n",
    "wind_direction_mode = original_df.loc[ original_df['Data_Hora'].dt.hour > 20, ['DirecaoDoVento_cat','Date']].groupby('Date')\\\n",
    "                        .apply(pd.DataFrame.mode).set_index('Date', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(wind_direction_mode, right_index=True, left_index=True)\n",
    "dummies = pd.get_dummies(X['DirecaoDoVento_cat'], drop_first=True)\n",
    "dummies.columns = [f'DirecaoDoVento_{i}' for i in range(len(dummies.columns))]\n",
    "X = pd.concat([X, dummies], axis = 1 ).drop(columns = ['DirecaoDoVento_cat'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "remove_columns = remove_high_correlation(X_train, 0.7)\n",
    "remove_columns += ['Precipitacao_min']\n",
    "X_test_sel = X_test.drop(columns = remove_columns)\n",
    "X_train_sel = X_train.drop(columns = remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_hyperopt = {\n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 5, 30, 1)),\n",
    "    'n_estimators':scope.int(hp.quniform('n_estimators', 5, 1000, 1)),\n",
    "    'min_child_weight':  scope.int(hp.quniform('min_child_weight', 1, 8, 1)),\n",
    "    'reg_lambda':hp.uniform('reg_lambda', 0.01, 500.0),\n",
    "    'reg_alpha':hp.uniform('reg_alpha', 0.01, 500.0),\n",
    "    'colsample_bytree':hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'early_stopping_rounds':  scope.int(hp.quniform('early_stopping_rounds', 1, 20, 1)),\n",
    "                 }\n",
    "\n",
    "def cost_function(params):\n",
    "    \n",
    "    fit_parameters = {}\n",
    "    fit_parameters['early_stopping_rounds'] = params.pop('early_stopping_rounds')\n",
    "\n",
    "    clf = xgb.XGBClassifier(**params,\n",
    "                            objective=\"binary:logistic\",\n",
    "                            random_state=42)\n",
    "\n",
    "    clf.fit(X_train_sel, y_train, eval_set = eval_set, eval_metric=[\"logloss\"], verbose = False,**fit_parameters)\n",
    "    y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "    return {'loss':-fbeta_score(y_test, y_pred, beta=2),'status': STATUS_OK}\n",
    "\n",
    "num_eval = 250\n",
    "eval_set = [(X_train_sel, y_train), (X_test_sel, y_test)]\n",
    "\n",
    "trials = Trials()\n",
    "best_param = fmin(cost_function,\n",
    "                     param_hyperopt,\n",
    "                     algo=tpe.suggest,\n",
    "                     max_evals=num_eval,\n",
    "                     trials=trials,\n",
    "                     rstate=np.random.RandomState(1))\n",
    "\n",
    "best_param['min_child_weight'] = int(best_param['min_child_weight'])\n",
    "best_param['n_estimators'] = int(best_param['n_estimators'])\n",
    "best_param['max_depth'] = int(best_param['max_depth'])\n",
    "best_param['early_stopping_rounds'] = int(best_param['early_stopping_rounds'])\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_param.copy()\n",
    "\n",
    "fit_parameters = {}\n",
    "fit_parameters['early_stopping_rounds'] = params.pop('early_stopping_rounds')\n",
    "\n",
    "clf = xgb.XGBClassifier(**params,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        random_state=42)\n",
    "\n",
    "clf.fit(X_train_sel, y_train, eval_set = eval_set, eval_metric=[\"logloss\"],\n",
    "        verbose = False,**fit_parameters)\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "y_pred_prob = clf.predict_proba(X_test_sel)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, ['0','1'])\n",
    "evaluate = (y_test, y_pred)\n",
    "print('f1_score: ', f1_score(*evaluate))\n",
    "print('Accuracy: ', accuracy_score(*evaluate))\n",
    "print('Precision: ', precision_score(*evaluate))\n",
    "print('Recall: ', recall_score(*evaluate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(y_test, y_pred_prob[:,1])\n",
    "fig.update_layout(template = 'plotly_dark')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda7e5673f44381479f842fe1694b809563"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
