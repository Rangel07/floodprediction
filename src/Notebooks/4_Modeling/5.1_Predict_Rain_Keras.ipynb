{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, fbeta_score\n",
    "\n",
    "from hyperopt import hp\n",
    "import hyperopt.pyll\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../Pipeline')\n",
    "\n",
    "from ml_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../../../data/cleandata/Info pluviometricas/Merged Data/repaired.csv', sep = ';')\n",
    "original_df['Data_Hora'] = pd.to_datetime(original_df['Data_Hora'])\n",
    "original_df['Date'] = original_df['Data_Hora'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols = list({c.split('_')[0] for c in original_df.columns if '_error' in c})\n",
    "interest_cols.remove('TemperaturaInterna')\n",
    "interest_cols.remove('SensacaoTermica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Stations - Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in interest_cols:\n",
    "    original_df[c] = (original_df[c+'_0'] + original_df[c+'_1'] +\n",
    "                      original_df[c+'_2'] + original_df[c+'_3'] + original_df[c+'_4'])/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = original_df[original_df.Data_Hora.dt.year == 2015]\n",
    "\n",
    "fig = go.Figure(layout=dict(template = 'plotly_dark'))\n",
    "\n",
    "for col in ['PontoDeOrvalho', 'Precipitacao', 'UmidadeRelativa', 'TemperaturaDoAr']:    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = df_plot['Data_Hora'],\n",
    "        y = df_plot[col],\n",
    "        name = col,\n",
    "                            )\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols += ['Diff_Temp_POrvalho']\n",
    "original_df['Diff_Temp_POrvalho'] = original_df['TemperaturaDoAr'] -  original_df['PontoDeOrvalho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 6\n",
    "sum = original_df['Precipitacao'].rolling(hours*4).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "has_rain_treshold = 10\n",
    "precipitacao_sum = original_df.loc[:, ['Date', 'Precipitacao']].groupby('Date').sum()\n",
    "precipitacao_sum.loc[:, 'Rain_Today'] = precipitacao_sum['Precipitacao'] > has_rain_treshold\n",
    "precipitacao_sum.loc[:, 'Rain_Next_Day'] = precipitacao_sum.loc[:, 'Rain_Today'].shift(-1)\n",
    "precipitacao_sum = precipitacao_sum.dropna()\n",
    "\n",
    "precipitacao_sum.index = pd.to_datetime(precipitacao_sum.index, yearfirst=True)\n",
    "precipitacao_sum.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datewise DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original_df[interest_cols + ['Date' , 'Data_Hora'] ]\n",
    "df = df.set_index('Data_Hora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = df.index.round('D').unique()\n",
    "df_date = pd.DataFrame(precipitacao_sum.index, columns = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df_date.merge(precipitacao_sum.loc[:, ['Rain_Today','Rain_Next_Day']], on = 'Date')\n",
    "df_date = df_date.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum_date = df[interest_cols + ['Date']].groupby('Date').sum()\n",
    "sum_date.columns = [c + '_sum' for c in sum_date.columns]\n",
    "\n",
    "median_date = df[interest_cols + ['Date']].groupby('Date').median()\n",
    "median_date.columns = [c + '_median' for c in median_date.columns]\n",
    "\n",
    "mean_date = df[interest_cols + ['Date']].groupby('Date').mean()\n",
    "mean_date.columns = [c + '_mean' for c in mean_date.columns]\n",
    "\n",
    "min_date = df[interest_cols + ['Date']].groupby('Date').min()\n",
    "min_date.columns = [c + '_min' for c in min_date.columns]\n",
    "\n",
    "max_date = df[interest_cols + ['Date']].groupby('Date').max()\n",
    "max_date.columns = [c + '_max' for c in max_date.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.concat([df_date, sum_date, mean_date, median_date, min_date, max_date], axis = 1)\n",
    "df_date.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [3, 9, 15, 21 ]\n",
    "for selected_hour in hours:\n",
    "\n",
    "    selected_df = df.loc[(df.index.hour == selected_hour ) & (df.index.minute == 0 ), interest_cols ]\n",
    "    selected_df.index = selected_df.index.round('D')\n",
    "    selected_df.columns = [f'{c}_{selected_hour}H' for c in selected_df.columns]\n",
    "    df_date = pd.concat([df_date, selected_df], axis = 1)\n",
    "\n",
    "df_date = df_date.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date['Rain_Next_Day'] = df_date['Rain_Next_Day'].astype(int)\n",
    "df_date['Rain_Today'] = df_date['Rain_Today'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_season(Row):\n",
    "    \n",
    "    doy = Row.name.timetuple().tm_yday\n",
    "    \n",
    "    fall_start = datetime.strptime('2020-03-20', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "    summer_start = datetime.strptime('2020-06-20', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "    spring_start = datetime.strptime('2020-09-22', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "    spring_end = datetime.strptime('2020-12-21', '%Y-%m-%d' ).timetuple().tm_yday\n",
    "    \n",
    "    fall = range(fall_start, summer_start)\n",
    "    summer = range(summer_start, spring_start)\n",
    "    spring = range(spring_start, spring_end)\n",
    "    \n",
    "    if doy in fall:\n",
    "        season = 1#'fall'\n",
    "    elif doy in summer:\n",
    "        season = 2#'winter'\n",
    "    elif doy in spring:\n",
    "        season = 3#'spring'\n",
    "    else:\n",
    "        season = 0#'summer' \n",
    "    \n",
    "    return season\n",
    "\n",
    "df_date['season'] =  df_date.apply(get_season, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_means = ['Precipitacao_mean']#, 'RadiacaoSolar_mean', 'TemperaturaDoAr_mean']\n",
    "\n",
    "for s in seasonal_means:\n",
    "    map_ = dict(df_date.groupby('season').mean()['Precipitacao_mean'])\n",
    "    df_date[f'seasonalMean_{s}'] =  df_date['season'].map(map_)\n",
    "\n",
    "df_date = df_date.drop(columns = ['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = df_date.drop(columns = ['Rain_Next_Day']), df_date.Rain_Next_Day.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train, X_test = sc.fit_transform(X_train), sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoding_dim = 25\n",
    "\n",
    "input_data = Input(shape=(X.shape[1],))\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='linear')(input_data)\n",
    "decoded = Dense(X.shape[1], activation=None)(encoded)\n",
    "autoencoder = Model(input_data, decoded)\n",
    "\n",
    "encoder = Model(input_data, encoded)\n",
    "\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=500,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = encoder.predict(X_train)\n",
    "encoded_data_test = encoder.predict(X_test)\n",
    "\n",
    "decoded_data_train = decoder.predict(encoded_data_train)\n",
    "decoded_data_test = decoder.predict(encoded_data_test)\n",
    "\n",
    "error_train = X_train - decoded_data_train\n",
    "error_test = X_test - decoded_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(x = list(range(error_train.shape[1] )), height =  error_train.mean(axis = 0))\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(x = list(range(error_test.shape[1] )), height =  error_test.mean(axis = 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_encoded = pd.DataFrame(encoded_data_train, columns = list(range(encoded_data_train.shape[1] )) )\n",
    "figure = plt.figure(figsize=(17,12))\n",
    "corrMatrix = df_encoded.corr()\n",
    "sns.heatmap(corrMatrix, annot=True, cbar = True, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {'colsample_bytree': 0.8937399605148961,\n",
    "         'early_stopping_rounds': 12,\n",
    "         'max_depth': 5,\n",
    "         'min_child_weight': 5,\n",
    "         'n_estimators': 729,\n",
    "         'reg_alpha': 19.86313897722475,\n",
    "         'reg_lambda': 188.1727458353706\n",
    "        }\n",
    "\n",
    "fit_params={}\n",
    "fit_params['early_stopping_rounds'] = params.pop('early_stopping_rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method = 'gpu_hist', **params)\n",
    "\n",
    "eval_set = [(encoded_data_train, y_train), (encoded_data_test, y_test)]\n",
    "\n",
    "clf.fit(encoded_data_train, y_train,  eval_metric=[\"logloss\",\"error\", \"auc\", \"map\"], \n",
    "        eval_set=eval_set, verbose=False, **fit_params);\n",
    "\n",
    "keys = clf.evals_result()['validation_0'].keys()\n",
    "\n",
    "fig, ax = plt.subplots( 1, len(keys), figsize = (7*len(keys),7))\n",
    "ax = ax.ravel()\n",
    "for i, key in enumerate(keys):\n",
    "    ax[i].set_title(key)\n",
    "    ax[i].plot(clf.evals_result()['validation_0'][key], lw = 3)\n",
    "    ax[i].plot(clf.evals_result()['validation_1'][key], lw = 3)\n",
    "plt.show()\n",
    "\n",
    "y_pred = clf.predict(encoded_data_test)\n",
    "plot_confusion_matrix(y_test, y_pred, ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = (y_test, y_pred)\n",
    "print('f1_score: ', f1_score(*evaluate))\n",
    "print('Accuracy: ', accuracy_score(*evaluate))\n",
    "print('Precision: ', precision_score(*evaluate))\n",
    "print('Recall: ', recall_score(*evaluate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred_prob = clf.predict_proba(encoded_data_test)\n",
    "fig = plot_precision_recall(y_test, y_pred_prob[:,1])\n",
    "fig.update_layout(template = 'plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=encoded_data_train.shape[1],\n",
    "                activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(encoded_data_train, y_train, epochs=150, batch_size=10, \n",
    "                    validation_data=(encoded_data_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(encoded_data_test) > 0.5 ).astype(int)\n",
    "plot_confusion_matrix(y_test, y_pred, ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = encoded_data_train.shape[0]\n",
    "pos = np.unique(y_train, return_counts=True)[1][1]\n",
    "neg = np.unique(y_train, return_counts=True)[1][0]\n",
    "\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=encoded_data_train.shape[1], activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "\n",
    "history = model.fit(encoded_data_train, y_train, epochs=150, batch_size=10, \n",
    "                    validation_data=(encoded_data_test, y_test), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(encoded_data_test)\n",
    "y_pred = (y_pred_proba  > 0.5 ).astype(int)\n",
    "plot_confusion_matrix(y_test, y_pred, ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(y_test, y_pred_prob)\n",
    "fig.update_layout(template = 'plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_recall = 0.8\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_prob)\n",
    "y_pred_threshold = (y_pred_prob > threshold[arg_nearest(recall, desired_recall)]).astype(int)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_threshold, ['0','1'])\n",
    "evaluate = (y_test, y_pred_threshold)\n",
    "print('f1_score: ', f1_score(*evaluate))\n",
    "print('Accuracy: ', accuracy_score(*evaluate))\n",
    "print('Precision: ', precision_score(*evaluate))\n",
    "print('Recall: ', recall_score(*evaluate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda7e5673f44381479f842fe1694b809563"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
